# implement delta index
import pickle
import os, sys, importlib
MICROBATCH_GENERATED_PATH = "/Users/pyadla/Downloads/CoFEE-master/main/cofee_edge_service/edge_user_data/stored_microbatches/"
sys.path.append('/Users/pyadla/Downloads/CoFEE-master/main/cofee_edge_service/')
from MicroBatch import MicroBatch


spatial_delta_index = {}
temporal_delta_index = {}
property_delta_index = {}

file_list = []

'''
# poll MICROBATCH GENERATED PATH for microbatches generated by sensors
def populate_file_list_of_microbatches():
    for file in os.listdir(MICROBATCH_GENERATED_PATH):
        if file.endswith('.pkl'):
            file_list.append(file)
'''
# add microbatches generated to delta index
def add_microbatch(microbatch_id, spatial_location, temporal_range, property, microbatch_object):
    spatial_delta_index[microbatch_id] = (spatial_location, microbatch_object.device_endpoint)
    temporal_delta_index[microbatch_id] = (temporal_range, microbatch_object.device_endpoint)
    property_delta_index[microbatch_id] = (property, microbatch_object.device_endpoint)

'''
# deserialize microbatches generated and stored by sensor onto directory
def deserialize_and_add_all_microbatches_to_delta_index():
    for f in file_list:
        fileObject = open(MICROBATCH_GENERATED_PATH+str(f), 'rb')
        microbatch_object = pickle.load(fileObject, errors='ignore')
        #print(microbatch_object.get_microbatch_prop())
        add_microbatch(microbatch_object.get_micro_batch_id(), microbatch_object.get_spatial_region(),
                   microbatch_object.get_timestamp(), microbatch_object.get_microbatch_prop(), microbatch_object)
'''
# print all delta indices
def print_delta_index():
    print(spatial_delta_index)
    print(temporal_delta_index)
    print(property_delta_index)


'''
# update delta indices
def update_delta_index():
    populate_file_list_of_microbatches()
    deserialize_and_add_all_microbatches_to_delta_index()
    print_delta_index()
'''


#update_delta_index()